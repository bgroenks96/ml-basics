{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Viterbi Algorithm for Hidden Markov Models (HMM)\n",
    "\n",
    "Hidden Markov Models are a way of modeling systems that have some kind \"hidden\" stateful process behind them. They are based on the Markov assumption:\n",
    "\n",
    "$P(s_t|s_1,s_2,...,s_{t-1})=P(s_t|s_{t-1})$\n",
    "\n",
    "Viterbi allows us to determine, given some set of observations ${y_1,y_2,...,y_T}$, the most likely sequence of states that generated those outputs (also called \"emissions\").\n",
    "\n",
    "We define our HMM as follows:\n",
    "\n",
    "Let $O = {o_1,o_2,...,o_N}$ be the *observational alphabet*, or the finite set of all possible observations.\n",
    "\n",
    "Let $S = {s_1,s_2,...,s_K}$ be the set of possible states.\n",
    "\n",
    "Let $A = a_{ij}$ where $a_{ij}$ is the probability of transitioning from state $i$ to state $j$ where $i,j\\in \\{1,...,K\\}$\n",
    "\n",
    "Let $B = b_{ij}$ where $b_{ij}$ is the probability of state $i$ \"emitting\" observation $j$ where $i\\in\\{1,...,K\\}$ and $j\\in\\{1,...N\\}$\n",
    "\n",
    "Let $\\Pi = \\{\\pi_1,\\pi_2,...,\\pi_K\\}$ where $\\pi_i$ is the prior probability of state $i$.\n",
    "\n",
    "*Note: We omit the formal specification of $O$ in the implementation below since it is not needed for the algorithm. We assume that all values included in the observation sequence $Y\\in\\{1,2,...,T\\}$, or more specifically,$Y\\in\\{0,1,...,T-1\\}$ when taking Python zero indexing into account.*\n",
    "\n",
    "So if we want to compute the probability of some sequence of observations $Y$ given some HMM $\\lambda$, we can do so as follows:\n",
    "\n",
    "$P(Y|\\lambda) = \\sum_S P(S|\\lambda)P(Y|S,\\lambda)$\n",
    "\n",
    "The algorithm for performing this computation has three main parts:\n",
    "\n",
    "(1) Initialization\n",
    "\n",
    "Set all of the emission probabilities at $t_0$ to their priors.\n",
    "\n",
    "For every $i$, set $V_{i,1} = \\pi_ib_{i,y_1}$ and $Q_{i,1} = 0$\n",
    "\n",
    "(2) Induction\n",
    "\n",
    "For every $i$ from $2$ to $T$ and every $j$ from $1$ to $N$, find the most likely path so far up to $j$:\n",
    "\n",
    "$V_{j,i} = \max_{1\\le k\\le K}(V_{k,i-1}a_{ij}b_{j,y_i})$\n",
    "\n",
    "$Q_{j,i} = \arg\max_{1\\le k\\le K}(V_{k,i-1}a_{ij})$\n",
    "\n",
    "(3) Backtracking\n",
    "\n",
    "Reconstruct the best possible state sequence computed by the induction step.\n",
    "\n",
    "$Z_T = \arg\max_{1\\le k\\le K}(V_{k,T})$\n",
    "\n",
    "For $t = T -1,T - 2,...,1$ : $Z_{t-1} = V_{Z_t,t}$ and $S*_{t-1} = S_{Z_{t-1}}$\n",
    "\n",
    "*Note: In the implementation below, $T_1$ is $V$ and $T_2$ is $Q$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, states, priors, transition_mat, emission_mat):\n",
    "        self.states = states\n",
    "        self.priors = priors\n",
    "        self.transition_mat = transition_mat\n",
    "        self.emission_mat = emission_mat\n",
    "    \n",
    "    # Implementation of Viterbi algorithm for simple HMM.\n",
    "    # https://en.wikipedia.org/wiki/Viterbi_algorithm\n",
    "    def viterbi(self, observations):\n",
    "        # Step 0. Definitions\n",
    "        # K is our number of possible states\n",
    "        K = len(self.states)\n",
    "        # S is our state space of length K\n",
    "        S = np.array(self.states)\n",
    "        # A is our transition probability table with dims KxK\n",
    "        A = np.array(self.transition_mat)\n",
    "        # B is our emissions probability table with dims KxN,\n",
    "        # where N is the number of possible observations\n",
    "        B = np.array(self.emission_mat)\n",
    "        # Pi is our array of priors for the initial state of length K\n",
    "        Pi = np.array(self.priors)\n",
    "        # Y is our sequence of observations y1,y2,...,yt\n",
    "        Y = np.array(observations)\n",
    "        T = len(Y)\n",
    "        # Index array for the best-path\n",
    "        Z = np.zeros(T, dtype=int)\n",
    "        # Best path, (x1,x2,...,xt)\n",
    "        X = [S[0]]*T\n",
    "        # Create our lookup table for the probability of the most likely path thus far:\n",
    "        # V_ij = (x1,x2,...,xj) with xj=si that generates our observations (y1,y2,...,yj)\n",
    "        V = np.zeros((K, T), dtype=float)\n",
    "        # Create our lookup table for the previous state of the most likely path thus far:\n",
    "        # Q_ij = (x1,x2,...,xj-1)\n",
    "        Q = np.zeros((K, T), dtype=int)\n",
    "        # Perform some assertions to make sure our parameters match specification.\n",
    "        assert A.shape == (K,K)\n",
    "        assert B.shape[0] == K\n",
    "        assert len(Pi) == K\n",
    "        assert T <= B.shape[1]\n",
    "        \n",
    "        # Step 1. Initialization\n",
    "        for i in xrange(K):\n",
    "            V[i,0] = Pi[i]*B[i,Y[0]]\n",
    "        \n",
    "        # Step 2. Induction\n",
    "        # For each state and observation, compute the most probable path at state j and observation i.\n",
    "        for (i, y) in enumerate(Y):\n",
    "            # Skip first iteration for Y; we want to start at second index.\n",
    "            # y2,y3,...,yT\n",
    "            if i == 0:\n",
    "                continue\n",
    "            for j in xrange(K):\n",
    "                p = [V[k,i-1]*A[k,j]*B[j,y] for k in xrange(K)]\n",
    "                Q[j,i] = np.argmax(p)\n",
    "                V[j,i] = p[Q[j,i]]\n",
    "                \n",
    "        # Step 3. Backtracking\n",
    "        # Rebuild most probable sequence of states.\n",
    "        Z[-1] = np.argmax(V[:,-1])\n",
    "        X[-1] = S[Z[-1]]\n",
    "        # Iterate descending from Y_len-1 (inclusive) to 0 (exclusive)\n",
    "        for i in xrange(T - 1, 0, -1):\n",
    "            Z[i-1] = Q[Z[i],i]\n",
    "            X[i-1] = S[Z[i-1]]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1]\n",
      "(0, 1, 2) -> [1, 2, 1]\n",
      "(0, 2, 1) -> [1, 1, 2]\n",
      "(1, 0, 2) -> [2, 1, 1]\n",
      "(1, 2, 0) -> [2, 1, 1]\n",
      "(2, 0, 1) -> [1, 1, 2]\n",
      "(2, 1, 0) -> [3, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "# Test on our hypothetical stock-prices example.\n",
    "states = [1, 2, 3]\n",
    "t_mat = np.array([[0.6,0.2,0.2],[0.5,0.3,0.2],[0.4,0.1,0.5]])\n",
    "e_mat = np.array([[0.7,0.1,0.2],[0.1,0.6,0.3],[0.3,0.3,0.4]])\n",
    "priors = [0.5,0.2,0.3]\n",
    "hmm = HMM(states, priors, t_mat, e_mat)\n",
    "\n",
    "print hmm.viterbi([0,0,0])\n",
    "\n",
    "from itertools import permutations\n",
    "Y_all = []\n",
    "for p in permutations(xrange(len(states))):\n",
    "    Y_all.append(p)\n",
    "for Y in Y_all:\n",
    "    print '{0} -> {1}'.format(Y, hmm.viterbi(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
